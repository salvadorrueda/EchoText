# EchoText - OpenAI Whisper Examples

Aquest repositori cont√© diversos exemples d'√∫s de **OpenAI Whisper** per a la transcripci√≥ de veu a text amb Python en entorns Ubuntu/Linux.

## üöÄ Instal¬∑laci√≥ R√†pida

He creat un script que configura autom√†ticament totes les depend√®ncies del sistema i l'entorn de Python:

```bash
chmod +x install.sh
./install.sh
```

L'script instal¬∑lar√† `ffmpeg`, `libportaudio2`, crear√† un entorn virtual (`venv`) i instal¬∑lar√† les llibreries de Python necess√†ries.

## üõ†Ô∏è Com utilitzar els exemples

Abans d'executar qualsevol script, activa l'entorn virtual:

```bash
source venv/bin/activate
```

### 1. Transcripci√≥ B√†sica (`whisper_simple.py`)
Transcripci√≥ directa d'un fitxer d'√†udio anomenat `sample.mp3`.
```bash
python3 whisper_simple.py
```

### 2. Transcripci√≥ Avan√ßada (`whisper_advanced.py`)
Detecta l'idioma autom√†ticament i mostra els segments amb marques de temps (timestamps).
```bash
python3 whisper_advanced.py
```

### 3. Transcripci√≥ en Viu (`whisper_live.py`)
Enregistra √†udio directament des del micr√≤fon i el transcriu quan prems la tecla "Enter".
```bash
python3 whisper_live.py
```

## üê≥ Docker

Tamb√© pots executar el servidor d'API utilitzant **Docker**. Aix√≤ √©s √∫til si no vols instal¬∑lar depend√®ncies localment o per desplegar el servidor en altres m√†quines.

### 1. Construir la imatge
```bash
docker build -t echotext-server .
```

### 2. Executar el container
```bash
docker run -p 5000:5000 echotext-server
```

### 3. Execuci√≥ amb GPU (NVIDIA)
Si tens una GPU NVIDIA i vols aprofitar l'acceleraci√≥ per hardware dins de Docker, necessites tenir instal¬∑lat el [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html).

Per defecte, el `Dockerfile` actual usa una imatge "slim" basada en CPU. Per usar GPU:
1. Canvia la base del `Dockerfile` a una amb CUDA (ex: `nvidia/cuda:11.8.0-base-ubuntu22.04`).
2. Executa el container amb el flag `--gpus`:
```bash
docker run --gpus all -p 5000:5000 echotext-server
```
### 4. Persist√®ncia del Model (Optimitzaci√≥)
Per evitar que Docker hagi de descarregar els 1.5 GB del model cada vegada que s'inicia el container, pots utilitzar un **volum**.

#### Opci√≥ A: Script d'ajuda (Recomanat)
He creat un script que gestiona autom√†ticament el volum i l'execuci√≥:
```bash
chmod +x start_docker_server.sh
./start_docker_server.sh
```

#### Opci√≥ B: Manualment amb Docker
Pots crear un volum i muntar-lo a la carpeta de mem√≤ria cau de Whisper (`/root/.cache/whisper`):
```bash
docker volume create whisper-models
docker run --gpus all -p 5000:5000 -v whisper-models:/root/.cache/whisper echotext-server
```

## üìã Requisits del sistema
Els scripts estan provats en **Ubuntu Desktop** i requereixen:
- Python 3.x
- **FFmpeg** (per processar l'√†udio) - *Ja incl√≤s a la imatge Docker.*
- **PortAudio** (per a l'enregistrament en viu) sudo apt-get install libportaudio2


---
*Creat com a part del projecte EchoText.*
